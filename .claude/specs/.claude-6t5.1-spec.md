# Spec: OTLP Integration for Workflow Metrics (Phase 2)

## Summary

Replace null token values in Phase 1's workflow metrics with real usage data extracted from subagent transcripts. The SubagentStop hook receives `agent_transcript_path` which contains API response messages including token counts. We parse these transcripts to extract and sum token usage, then calculate costs using model-specific pricing.

## Key Technical Finding

OTLP metrics are NOT directly accessible from hooks. However, the `agent_transcript_path` field in SubagentStop hooks points to a JSONL transcript file that contains all API responses with usage data. This is our data source.

## Transcript Format (verified from actual files)

Each line in the transcript is a JSON object. Messages of type `assistant` contain:

```json
{
  "type": "assistant",
  "message": {
    "model": "claude-opus-4-5-20251101",
    "usage": {
      "input_tokens": 3,
      "cache_creation_input_tokens": 4187,
      "cache_read_input_tokens": 0,
      "output_tokens": 21,
      "cache_creation": {
        "ephemeral_5m_input_tokens": 4187,
        "ephemeral_1h_input_tokens": 0
      }
    }
  }
}
```

## Requirements

- [ ] Modify `metrics-end.sh` to read `agent_transcript_path` from hook input
- [ ] Parse transcript JSONL to extract all assistant messages with usage data
- [ ] Sum token counts across all API calls:
  - `tokens.input` = sum of `usage.input_tokens`
  - `tokens.output` = sum of `usage.output_tokens`
  - `tokens.cache_read` = sum of `usage.cache_read_input_tokens`
  - `tokens.cache_creation` = sum of `cache_creation.ephemeral_5m_input_tokens` + `cache_creation.ephemeral_1h_input_tokens`
- [ ] Extract model name from last assistant message (captures primary model used)
- [ ] Calculate cost_usd using token counts and model-specific pricing
- [ ] Update bd comment format to show real values instead of placeholders

## Edge cases

- [ ] Missing transcript file - use null values for all token fields
- [ ] Empty transcript (no API calls) - use zero for tokens, null for model
- [ ] Multiple models in transcript - use last model name
- [ ] Malformed JSON lines in transcript - skip and continue processing
- [ ] Transcript path not in hook input - graceful fallback to null values

## Cost Calculation Formula

Per 1M tokens (MTok):

| Model Pattern | Input $/MTok | Output $/MTok | Cache Read $/MTok | Cache 5m Write $/MTok |
|---------------|--------------|---------------|-------------------|----------------------|
| opus-4.5 | 5.00 | 25.00 | 0.50 | 6.25 |
| opus-4 | 15.00 | 75.00 | 1.50 | 18.75 |
| sonnet-4 | 3.00 | 15.00 | 0.30 | 3.75 |
| haiku-4.5 | 1.00 | 5.00 | 0.10 | 1.25 |
| haiku-3.5 | 0.80 | 4.00 | 0.08 | 1.00 |

```
cost_usd = (input_tokens * input_rate / 1000000) +
           (output_tokens * output_rate / 1000000) +
           (cache_read_tokens * cache_read_rate / 1000000) +
           (cache_creation_tokens * cache_write_rate / 1000000)
```

## Acceptance criteria

- [ ] Real token counts appear in workflow-metrics.jsonl stage_end events
- [ ] Real cost_usd values calculated correctly based on model pricing
- [ ] Model name populated (e.g., "claude-opus-4-5-20251101")
- [ ] JSONL schema unchanged (same field names, just values populated)
- [ ] bd comments show real metrics instead of "--"
- [ ] Existing jq queries still work on JSONL file
- [ ] Hook continues to exit 0 on all errors (no workflow disruption)

## Out of scope

- 1-hour cache writes (use 5m rate for simplicity - 1h caches are rare)
- Cost optimization recommendations
- Historical backfill of Phase 1 data
- Concurrent subagent support

## Files to modify

### Modified files

- `/Users/tomas/.claude/hooks/metrics-end.sh` - Add transcript parsing and cost calculation

### No new files required

## BD Comment Format (updated)

```markdown
## Stage Metrics
- **Stage**: analyst
- **Task**: Implement feature X
- **Duration**: 1m 47s
- **Tokens**: 12,345 in / 1,234 out / 8,901 cache
- **Cost**: $0.0523
- **Model**: claude-sonnet-4-5-20250929
- **Session**: abc123
- **Recorded**: 2026-02-03T14:25:32Z
```

## Implementation Notes for Planner

1. **Transcript parsing approach**: Use jq to filter lines with `type == "assistant"` and extract usage data. Sum values with jq's `add` function.

2. **Model pricing function**: Create a bash function that maps model name patterns to pricing. Use grep/case statement to match model family.

3. **Cost calculation in bash**: Bash doesn't handle decimals well. Options:
   - Use awk for floating point math
   - Use bc command if available
   - Calculate in millionths then format

4. **agent_transcript_path location**: The path is in SubagentStop input at `.agent_transcript_path`, different from the main `.transcript_path`.

5. **Fallback chain**: If any parsing fails, fall back to null values (matching Phase 1 behavior). Never break the hook.

## Artifacts consulted

- `WORKFLOW.md`: Confirmed bd comments as primary output mechanism
- `lessons-learned.md`: Applied jq for safe JSON handling, exit 0 always pattern

## Artifacts to update

- None - internal infrastructure change

## Open risks

1. **Transcript format stability**: The transcript JSONL format is not officially documented. Changes in Claude Code versions could break parsing. Mitigation: defensive parsing with fallbacks.

2. **Cache pricing complexity**: Transcripts show 5m and 1h cache separately but we use 5m rate for simplicity. This slightly underestimates costs for 1h cached content (rare case).

3. **Model name parsing for pricing**: Model names like "claude-opus-4-5-20251101" need pattern matching to determine pricing tier. Fallback to sonnet pricing if unknown model.
